### This file has code for filling SQL databases with telemetry data.  It 
### is meant to be used in conjunction with 'SQL db create.r'...
### 

### Each deployment has a different database: 
#     dbhb2007, dbhb2008, dbhb1, dbhb2, dbhb3, dbsb1, dbsb2, dbsb3, dbsb4
### Each database has the following tables
#     1. sdl41 - holding raw SDL data, from text version of *.bin files
#        (dati fraction, power, port, tagID, type, rawSensor, gpsSync)
#     2. misclines - for random lines that don't appear to have data
#     3. toa41 - holding toa data, from *.toa files generated by ALPS
#         (???)
#     4. posF60100 (for example) - holding position estimates from 
#         "T60100B1 no psr.txt" files created by ALPS IS THIS TRUE
#         OR DO THESE HOLD POSITIONS OF ALL FISH ON A SINGLE REEF ?????


# required packages
library(RMySQL)
library(chron)


###############################################################################
##############################################################################
### IMPORT RAW SDL DATA from an sdl in SYMBOL mode THEN SAVE AS MySQL DATABASES
##############################################################################
# To use this function, the database and tables should already be defined 
#   and connected
# This function imports data from the text version of *.bin files.
# It overwrites existing data.  
#
# One table per SDL holds tagID arrival times.
fillSdlSQLtable = function(deployment, sdl){  # deployment = "hb2007"; sdl=41;
  # settings that change for each deployment
  for (i in 1:length(md)){ # i loops through all deployments
    if (deployment == md[[i]]$deployment){
      tempDir = md[[i]]$homeDir
      downloadDate = md[[i]]$sdlDownloadDate
      timezone = md[[i]]$timezone
    }  
  }
  
  # set the database and connect
  dbName = paste("db",deployment,sep="")# connect to the database
  dbcon = dbConnect(MySQL(), user="root", password="zy0014", dbname=dbName)
  
  # make the dbTable names
  sdlTableName = paste("sdl",sdl,sep="")
  miscTableName =  "miscLines"
  # make sure the dbTables are empty of lines before starting
  dbphrase = paste("DELETE from", sdlTableName, ";")   
  res = dbSendQuery(dbcon, dbphrase)                
  
  # set directory and file name
  oDir = getwd()
  cDir = paste(tempDir, "/SDL data", sep="")    
  setwd(cDir)
  
  # set the file to read
  readfile = paste("SN2650", sdl, "_",downloadDate,".txt", sep="") 
  
  # some line book keeping
  lineCount = 0 # a line counter
  headerLineCount = 0 # number oflines in the header (first data line = 
                      # headerLineCount+1)
  baseChunk = 50000 # how many rows at a time to read/import from text file
  
  # Each data line has either 7 (code mode) or 9 columns (symbol mode)
  # some years were collected in symbol mode and some in code mode, and 
  # even within a single file, there are data lines of 7 or 9 columns
  runsOf7 = 7
  runsOf9 = 9
  # Sometimes these lines get mixed, for some reason...there are 7 and 9 column
  # lines mixed in the same file.  I need a way to read in 7/9 column lines
  # and put them in the right files.  For 7 column lines, I'll add NA in the 
  # correct places and save everything into a 9 column dbTable  
  colNames7 = c("date", "time", "fraction", "power", "port", "tagID", "gpsSync")
  colClasses7 = c('character','character','integer','integer','integer',
    'integer','character')
  colNames9 = c("date", "time", "fraction", "power", "port", "tagID", 
    "type", "rawSensor", "gpsSync")
  colClasses9 = c('character','character','integer','integer','integer',
    'integer','integer','integer','character')
  
  # open the file to read from
  rfile = file(readfile, open="rt") # open the connection
  
  # count fields in each line, a field is separated by white space
  fcount = count.fields(rfile, blank.lines.skip=FALSE)   
  # look for runs in 'fcount', 1 line with 7 fields, 3 lines with 1 fiedls, etc.
  # in 'SN265041_18jan08.txt' data lines have 7 fields (ID only tags) or 9 
  # fields (ID + sensors)
  # rle tells you the length of each run, not the line number
  runs = rle(fcount)
  
  # breakLines are line numbers of the END of runs (for runs of 1, it is also 
  # the start)
  # to get the first line of a run, runEndLineNum - lengthOfRun + 1
  breakLines = c(rep(NA,length(runs$lengths)))
  for (i in 1:length(breakLines)){breakLines[i]=sum(head(runs$lengths,i))}
  
  fieldCounts = cbind(
    "numFields"=runs$values,
    "lengthOfRun"=runs$lengths,
    "runStartLineNum"=breakLines-runs$lengths+1
  )
  # to get the first line of a run, runEndLineNum - lengthOfRun + 1
  # first line of bad (not 9 columns) or good (9 columns) data in the file, 

  # because R automatically closes the connection...reopen it
  rfile = file(readfile, open="rt") # open the connection
     
  # read and discard the header
  go=TRUE
  while (go) {
    temp1 = readLines(rfile, n=1)
    headerLineCount = headerLineCount + 1
    if (regexpr("Tag ID Detection Reports", temp1) > -1){go=FALSE} # stop discarding  
  }
  # now read and discard 3 more lines to move to the first data line
  readLines(rfile,n=3)
  headerLineCount = headerLineCount + 3 

  # now get rid of the lines/runs corresponding to the header
  fieldCounts = data.frame(fieldCounts[fieldCounts[,3] > headerLineCount,])
  # the first column is the number of fields (separated by white space) per line
  # the second column is the nubmer of lines with the value in the first column
  # the third column is the actual file line number of the first line of a run - a 
  # block of similar values.
  
  # read in lines...if a line has 7 fields (meaning it's an ID only tag line) 
  # add two NA columns, if it has 9 fields (meaning it's a sensor tag line) 
  # don't add lines.  Then save either into the dbTable.
   
  
  for (i in 1:nrow(fieldCounts)){ # a loop for handling all runs
    # check to see how many fields there are in the first run
    if (fieldCounts$numFields[i] == runsOf7){ #  
      # some runs can be very long, so I want to read in and write out chunks
      # at a time, not the entire run...
      
      # set some starting values
      chunk = baseChunk # this is the currentChunk
      rRunLines = fieldCounts$lengthOfRun[i] # remainingRunLines
      go = TRUE # this will run the loop until rRunLines are all read in
      
      # Start cycling through the current run, 'chunks' at a time
      while (go){ # while there are still rRunLines to be read from current run
        if (chunk < rRunLines){ # if this isn't the final chunk...
          # chunk remains unchanged
          rRunLines = rRunLines - chunk
        } else { # chunk >= rRunLines
          chunk = rRunLines
          go = FALSE
        }
        
        # now read chunk lines from the table  
        temp1 = read.table(rfile, na.strings="N/A",
          col.names=colNames7, colClasses=colClasses7, nrow=chunk)
        # add two NA columns
        temp2 = cbind(temp1[,1:6], "type"=NA, "rawSensor"=NA, "gpsSync"=temp1[,7], 
          stringsAsFactors=FALSE)
        # get date/time into utime (GMT), datiL, and datiG
        # change $date format
        tempDate = format(as.Date(temp2$date,format="%m/%d/%y"),"%Y-%m-%d")
        # drop the seconds fraction
        tempTime = substr(temp2$time, 1, 8)
        # combine date and time into dati
        tempDati = paste(tempDate, tempTime)
        # What time zone are these times?
        if (timezone=="EST" || timezone=="EDT"){ 
          tempTimezone = "EST5EDT" } else if (timezone == "GMT") {
          tempTimezone = timezone
        }
        # convert from chr to utime (GMT)
        datiVec1 = unclass(as.POSIXct(strptime(tempDati, "%Y-%m-%d %H:%M:%S", 
          tz=tempTimezone), origin="1970-1-1", tz=tempTimezone))
        # remove the tz attribute from datiVec1
        attributes(datiVec1) = NULL
        # convert to datiG
        datiVec2 = as.POSIXlt(datiVec1, origin="1970-1-1", tz="GMT")  
        #convert to datiL                                
        datiVec3 = as.POSIXlt(datiVec1, origin="1970-1-1", tz="EST5EDT")  
        # combine things into the right order
        temp3 = cbind("utime"=datiVec1, "datiG" = datiVec2, "datiL" = datiVec3, temp2[,3:9])    
        # write temp3 to dbTable                
        dbWriteTable(dbcon, sdlTableName, temp3, append=TRUE, row.names=0)        
      } # end while(go)
      
    } else if (fieldCounts$numFields[i] == runsOf9){ # 
      # some runs can be very long, so I want to read in and write out chunks
      # at a time, not the entire run...
      
      # set some starting values
      chunk = baseChunk # this is the currentChunk
      rRunLines = fieldCounts$lengthOfRun[i] # remainingRunLines
      go = TRUE # this will run the loop until rRunLines are all read in
      
      # Start cycling through the current run, 'chunks' at a time
      while (go){ # while there are still rRunLines to be read from current run
        if (chunk < rRunLines){ # if this isn't the final chunk...
          # chunk remains unchanged
          rRunLines = rRunLines - chunk
        } else { # chunk >= rRunLines
          chunk = rRunLines
          go = FALSE
        }
        
        # now read chunk lines from the table        
        temp1 = read.table(rfile, na.strings="N/A",
          col.names=colNames9, colClasses=colClasses9, nrows=chunk)
        # get date/time into utime (GMT), datiL, and datiG
        # change $date format
        tempDate = format(as.Date(temp1$date,format="%m/%d/%y"),"%Y-%m-%d")
        # drop the seconds fraction
        tempTime = substr(temp1$time, 1, 8)
        # combine date and time into dati
        tempDati = paste(tempDate, tempTime)
        # What time zone are these times?
        if (timezone=="EST" || timezone=="EDT"){ 
          tempTimezone = "EST5EDT" } else if (timezone == "GMT") {
          tempTimezone = timezone
        }
        # convert from chr to utime (GMT)
        datiVec1 = unclass(as.POSIXct(strptime(tempDati, "%Y-%m-%d %H:%M:%S", 
          tz=tempTimezone), origin="1970-1-1", tz=tempTimezone))
        # remove the tz attribute from ???
        attributes(datiVec1) = NULL
        # convert to datiG
        datiVec2 = as.POSIXlt(datiVec1, origin="1970-1-1", tz="GMT")  
        #convert to datiL                                
        datiVec3 = as.POSIXlt(datiVec1, origin="1970-1-1", tz="EST5EDT")  
        # combine things into the right order
        temp2 = cbind("utime"=datiVec1, "datiG"=datiVec2, "datiL"=datiVec3, temp1[,3:9]) 
       
        dbWriteTable(dbcon, sdlTableName, temp2, append=TRUE, row.names=0)
      } # end while(go)  
    } else { # we've entered the footer --- this code only works if there are
             # no funky lines within the good data lines before the footer   
      print(paste("There's a funky line/lines at run =", i))
      rRunLines = 100 # just grab all the rest of the lines...fieldCounts$lengthOfRun[i]
      temp1 = readLines(rfile, n=rRunLines)
      temp2 = paste("db=", dbName, ", sdl=", sdl, ": ", temp1, sep="")
      dbphrase = paste("INSERT INTO", miscTableName, "VALUES ('", temp2, "');")
      for (j in 1:length(dbphrase)){res=dbSendQuery(dbcon, dbphrase[j])}
      # to signal we've entered the footer, handled all the lines and should 
      # exit the i-loop
      break()
    }
  } # end for loop over 'fieldCount'
  
  # close the file
  close(rfile) # close the file connection
  # close the dbConnection 
  dbDisconnect(dbcon)
  # return to original directory
  setwd(tempDir)    
} # end of fillSdlSQLtable()   
###############################################################################
###############################################################################


###############################################################################
###############################################################################
### These lines fill tables with raw SDL data...that is one table per SDL with
### all tagID arrival times

# the following lines take a long time...
sdls=41:45
# 2007
fillSdlSQLtable("hb2007", 41)
for (i in 1:5){ fillSdlSQLtable("hb2007", sdls[i]) }
# 2008
for (i in 1:5){ fillSdlSQLtable("hb2008", sdls[i]) }
# 2009
for (i in 1:5){ fillSdlSQLtable("sb1", sdls[i]) }
for (i in 1:5){ fillSdlSQLtable("sb2", sdls[i]) }
for (i in 1:5){ fillSdlSQLtable("sb3", sdls[i]) }
for (i in 1:5){ fillSdlSQLtable("sb4", sdls[i]) }
for (i in 1:5){ fillSdlSQLtable("hb1", sdls[i]) }
for (i in 1:5){ fillSdlSQLtable("hb2", sdls[i]) }
for (i in 1:5){ fillSdlSQLtable("hb3", sdls[i]) }









###############################################################################
###############################################################################
###############################################################################
###############################################################################
##############################################################################
### IMPORT toa DATA from ALPS decompressing THEN SAVE AS MySQL DATABASES
##############################################################################
# to use this function, the database and tables should already be defined 
# 
# This function is incomplete because I decided to make one table per tag instead
# of one table per tag for each SDL.  This function hasn't been completely 
# modified for that change.
#
### for use with any deployment.
fillToaSQLtable = function(deployment, tagName){ 
  # deployment="sb1"; tagName="f24"; 
  
  # settings that change for each deployment
  for (i in 1:length(md)){ # i loops through all deployments
    if (deployment == md[[i]]$deployment){
      tempDir = md[[i]]$homeDir
    }  
  }
 
  # set the database and connect
  dbName = paste("db",deployment,sep="")
  dbcon = dbConnect(MySQL(), user="root", password="zy0014", dbname=dbName)
  # make the database table names           
  toaTableName = paste("toa", tagName, sep="")
  # make sure the dbTables are empty of lines before starting
  dbphrase = paste("DELETE from", toaTableName, ";")    
  res = dbSendQuery(dbcon, dbphrase)                    
 
  # set directory and file name
  oDir = getwd()
  cDir = paste(tempDir, "/ALPS", sep="")    
  setwd(cDir)

  # now use another function to import toa data, a list of data.frames
  temp1 = importToaData(tagName=tagName, deployment=deployment)          
  # if this becomes too long later on, read in by chunks like in 'fillSdlSQLtable()'
  # if I want to make uTime as date and time before going into database:, see 'fillSdlSQLtable()'
  
  # add a column containing sdl number, convert utime to readable time
  sdlNumber = 41:45
  temp2=temp1
  
  ########################################################### I THINK THE SDLs WERE IN LOCAL TIME SOMETIMES AND IN GMT SOMETIMES...THAT WILL CHANGE, THESE LINES
  for (i in 1:5){ # for all 5 SDLs)
    # if the SDL utime output is in GMT...
    # convert from utime to readable time, as POSIXct, but in correct dati format 
    # convert to datiG
    datiVec2 = as.POSIXlt(temp2[[i]]$utime, origin="1970-1-1", tz="GMT")  
    #convert to datiL                                
    datiVec3 = as.POSIXlt(temp2[[i]]$utime, origin="1970-1-1", tz="EST5EDT")  

    # for some reason doing anything to the entire vector tempTimes (like
    # simply 'R>datiVec2' or 'R>str(datiVec2)') crashes R...so I will   
   
    datiVec2a = vector(length=length(datiVec2))
    datiVec3a = vector(length=length(datiVec3))
    for (j in 1:length(datiVec2)){
      datiVec2a[j] = format(datiVec2[j])
      datiVec3a[j] = format(datiVec3[j])
    }
    # add/remove columns
    temp2[[i]] = cbind("utime"=temp2[[i]]$utime, "datiG"=datiVec2a, 
      "datiL"=datiVec3a, temp2[[i]][2:5], "sdlNumber"=sdlNumber[i])
    # write the data.frames to a MySQL database 
    dbWriteTable(dbcon, toaTableName, temp2[[i]], append=TRUE, row.names=0)
  }
  
  # close the dbConnection 
  dbDisconnect(dbcon)
  # return to original directory
  setwd(oDir)    
} # end of fillToaSQLtable()  
##############################################################################
### END IMPORT toa DATA from ALPS decompressing THEN SAVE AS MySQL DATABASES
##############################################################################
#fillToaSQLtable(deployment="hb2008", tagName="b80") 
 
# fill the hb2007 tables
md[[1]]$deployment
allTagNames = md[[1]]$allTagNames

for (i in 1:length(allTagNames)){
  fillToaSQLtable(deployment="hb2007", tagName=allTagNames[i])
}



# fill the hb2008 tables
# because hb2008 was such a problem deployment, do this for all possible tag codes
codeNames = paste("c", 1:130, sep="")

for (i in 1:length(codeNames)){
  fillToaSQLtable(deployment="hb2008", tagName=codeNames[i])
}








































look down                look down      for retired functions



###############################################################################
###############################################################################
###############################################################################
###############################################################################
### This has been retired............ and replaced with a more general function
##############################################################################
### IMPORT RAW SDL DATA from one sdl (either code or symbol mode) THEN SAVE AS MySQL DATABASES
##############################################################################
# to use this function, the database and tables should already be defined and connected
fillSdlSQLtable = function(deployment, sdl){ # year = 2009; deployment="hb2007"; sdl=44;

 
  # set the database
  dbName = paste("db",deployment,sep="")
  
  # settings that change for each deployment
  for (i in 1:length(md)){ # i loops through all deployments
    if (deployment == md[[i]]$deployment){
      tempDir = md[[i]]$homeDir
      downloadDate = md[[i]]$sdlDownloadDate
    }  
  }
  
  # set directory and file name
  oDir = getwd()
  cDir = paste(tempDir, "/SDL data", sep="")    
  setwd(cDir)
 
  # pick the file to read
  readfile = paste("SN2650", sdl, "_",downloadDate,".txt", sep="") 

  # make the database table names
  sdlTableName = paste("sdl",sdl,sep="")
  miscTableName =  "miscLines"
    
  ### to run the following lines individually evaluate this line...
  ### setwd("C:/zy/telemetry/2009/2009Jun01 if43/raw SDL output")
  ### readfile = "SN265041_17Jun09.txt"
  
  # open the file to read from
  rfile = file(readfile, open="rt") # open the connection
  
  # first scan it to count header, data, and footer lines
  temp1 = scan(rfile, what="character", sep="\n", blank.lines.skip = FALSE)
  #close(rfile)
   
  entireLineCount = length(temp1)
  
  # find out how many lines are in the header (counting blank lines)
  for (i in 1:length(temp1)){
    testline = temp1[i]
    if (regexpr("Tag ID Detection Reports", testline) > -1){
      headerLineCount = i + 3
      break # break out of the 'for' loop checking all gazillion lines
    }
  }

  # find out how many lines are in the footer (counting blank lines)
  # check from the last row, upwards to find "Warnings and Alerts"  
  for (i in length(temp1):1){  
    testline = temp1[i]
    if (regexpr("Warnings and Alerts", testline) > -1){
      footerLineCount = entireLineCount - i + 2 # 'i' is the row number of the "W and A" line
      break # break out of the 'for' loop checking all gazillion lines
    } # end 'if' we're on the "Warnings and Alerts" line
  } # 
    
  # READ IN THE HEADER AND DISCARD
  # connect to the database
  dbcon = dbConnect(MySQL(), user="root", password="zy0014", dbname=dbName)
  # re-open the connection and get back to start
  rfile = file(readfile, open="rt") 
  # read and put the header in 'sdlHeaderTableName'
  temp1 = readLines(rfile, n=headerLineCount) # read in the header lines line
  ## temp1 must be a data.frame to go into a database
  #temp2 = as.data.frame(cbind("headerLine"=temp1), stringsAsFactors = FALSE)
  ## confirm the table is there and empty
  #dbRemoveTable(dbcon, sdlHeaderTableName)
  ## write the header to an SDl table, 'sdlHeaderTableName'
  #dbWriteTable(dbcon, sdlHeaderTableName, temp2, append=TRUE, row.names=0)
  
  # READ IN THE DATA
  # how many data lines, etc.
  dataLineCount = entireLineCount - headerLineCount - footerLineCount
  
  chunkSize = 50000 # really 500000
  numFullChunks = floor(dataLineCount / chunkSize)
  remainingLineCount = dataLineCount  - (numFullChunks * chunkSize)
  
  # confirm the table is there and empty
  dbRemoveTable(dbcon, sdlTableName)
  # read in detection data, full chunks at a time
  for (i in 1:numFullChunks){
    temp1 = read.table(rfile, na.strings="N/A",
      col.names=c("date", "time", "fraction", "power", "port", "tagID", "gpsSync"), 
      colClasses=c('character','character','integer','integer','integer',
      'character','character'),
      comment.char = "",  # the help file says this makes it faster 
      nrows=chunkSize)
    # change format of date and time
    temp1$date = format(as.Date(temp1$date,format="%m/%d/%y"),"%Y-%m-%d")  
    temp1$time = as.numeric(chron(times.=substr(temp1$time,1,8))) 
      # chron can't show subseconds but keeps them...
      # I don't want them, I'll recalculate it from the column "fraction"         
    dbWriteTable(dbcon, sdlTableName, temp1, append=TRUE, row.names=0)
  } # end for loop over full chunck    
  
  # read in detection data, from the last, partial chunk
  temp1 = read.table(rfile, na.strings="N/A",
    col.names=c("date", "time", "fraction", "power", "port", "tagID", "gpsSync"), 
    colClasses=c('character','character','integer','integer','integer',
    'character','character'),
    comment.char = "",  # the help file says this makes it faster 
    nrows=remainingLineCount)
  # change format of date and time
  temp1$date = format(as.Date(temp1$date,format="%m/%d/%y"),"%Y-%m-%d")  
  temp1$time = as.numeric(chron(times.=substr(temp1$time,1,8))) 
    # chron can't show subseconds but keeps them...
    # I don't want them, I'll recalculate it from the column "fraction"       
  dbWriteTable(dbcon, sdlTableName, temp1, append=TRUE, row.names=0)
  
  # READ IN THE FOOTER
  # read and put the header in 'sdlHeaderTableName'
  temp1 = readLines(rfile, n=footerLineCount) # read in the footer lines
  # temp1 must be a data.frame to go into a database
  temp2 = as.data.frame(cbind("headerLine"=temp1), stringsAsFactors = FALSE)
  # write the footer to an SQL table, 'sdlHeaderTableName'
  dbWriteTable(dbcon, sdlHeaderTableName, temp2, append=TRUE, row.names=0)  
    
  
  # close the file
  close(rfile) # close the file connection
  # close the dbConnection if you knew what it was
  # dbDisconnect(dbcon2009hb1)
  
  # return to original directory
  setwd(oDir)    
} # end of fillSdlSQLtable()  
# fillSdlSQLtable(year=2009, deployment="of43", sdl=44)

fillSdlSQLtable(year=2009, deployment="hb1", sdl=41)
fillSdlSQLtable(year=2009, deployment="hb1", sdl=42)
fillSdlSQLtable(year=2009, deployment="hb1", sdl=43)
fillSdlSQLtable(year=2009, deployment="hb1", sdl=44)
fillSdlSQLtable(year=2009, deployment="hb1", sdl=45)












This function has been retired...fillSdlSymbolSQLtable should now do this...
### CODE  
##############################################################################
### IMPORT RAW SDL DATA from an sdl in CODE mode THEN SAVE AS MySQL DATABASES
##############################################################################
# to use this function, the database and tables should already be defined and connected
fillSdlCodeSQLtable = function(year, sdl){ 
  # year=2008; sdl=41;

  lineCount = 0; # just a line counter
  headerLineCount = 0; # number of lines in the header (first data line = headerLineCount+1)
  # year=2008; sdl=41;
  
  # set directory and file name
  tempDir = getwd() 
  if (year==2007){
    ### record current directory and change to desired SDL directory
    directory = "C:/zy/SDL/2007 raw"            
    outputDir = "C:/zy/SDL/2007 other files"            
    setwd(directory)
    if (sdl==42 || sdl==44 || sdl==45){
      readfile = paste("SN2650",sdl,"_17jan08.txt",sep="") #readfile = paste("SN2650",sdl,"_17jan08_short.txt",sep="") #
    } else {
      readfile = paste("SN2650",sdl,"_18jan08.txt",sep="") #readfile = paste("SN2650",sdl,"_18jan08_short.txt",sep="") #
    }
  }  else if (year==2008){
    ### record current directory and change to desired SDL directory
    directory = "C:/zy/telemetry/2008/2008 some date/raw SDL output"
    setwd(directory)
    readfile = paste("SN2650",sdl,"_19Dec08_short.txt",sep="") #paste("SN2650",sdl,"_19Dec08.txt",sep="") #
                                                      
  }
  # make the database table name
  dbTname = paste("sdl",sdl,sep="")
  dbTnameMisc =  "miscLines"
  
  
  ### to run the following lines individually evaluate this line...
  ### setwd("C:/zy/SDL/2007 raw")
  ### readfile = "SN265041_19Dec08.txt"
  ### readfile = "SN265041_18Jan08-short.txt"
  
  # open the file to read from
  rfile = file(readfile, open="rt") # open the connection
 
  # read and discard the header
  go=TRUE
  while (go) {
    temp1 = readLines(rfile, n=1)
    headerLineCount = headerLineCount + 1
    if (regexpr("Tag ID Detection Reports", temp1) > -1){go=FALSE} # stop discarding  
  }
  # now read and discard 3 more lines to move to the first data line
  readLines(rfile,n=3)
  headerLineCount = headerLineCount + 3 

  # make sure the dbTable is empty of lines before starting
  dbphrase = paste("DELETE from", dbTname, ";")  
  res = dbSendQuery(dbcon, dbphrase)

  # read in chunks at a time
  chunk = 500 #500000
  go = TRUE
  while (go){
    temp1 = read.table(rfile, na.strings="N/A",
      col.names=c("date", "time", "fraction", "power", "port", "tagID", "gpsSync"), 
      colClasses=c('character','character','integer','integer','integer',
      'character','character'), 
      nrows=chunk)
    # check to see if we've reached the end  
    if (nrow(temp1) == chunk){ # if this is true then we haven't reached the end   
      # change format of date and time
      temp1$date = format(as.Date(temp1$date,format="%m/%d/%y"),"%Y-%m-%d")  
      temp1$time = as.numeric(chron(times.=substr(temp1$time,1,8))) 
          # chron can't show subseconds but keeps them...
          # I don't want them, I'll recalculate it from the column "fraction"       
      dbWriteTable(dbcon, dbTname, temp1, append=TRUE, row.names=0)
    } else { # we've read in the last chunk; fewer than 'chunk' lines
      # ... remove the last four and write the rest to the database
      endrow = nrow(temp1)# find last row
      temp2 = temp1[-(endrow):-(endrow-3),]
      # change format of date and time
      temp1$date = format(as.Date(temp1$date,format="%m/%d/%y"),"%Y-%m-%d")  
      temp1$time = as.numeric(chron(times.=substr(temp1$time,1,8))) 
          # chron can't show subseconds but keeps them...
          # I don't want them, I'll recalculate it from the column "fraction"
      dbWriteTable(dbcon, dbTname, temp2, append=TRUE, row.names=0)
      
      # exit the while loop
      go = FALSE    
    }   
  } # end while loop
  
  # return to original directory
  setwd(tempDir)    
} # end of sdlCodeSQLtable()  

fillSdlCodeSQLtable(2008,41)
fillSdlCodeSQLtable(2008,42)
fillSdlCodeSQLtable(2008,43)
fillSdlCodeSQLtable(2008,44)
fillSdlCodeSQLtable(2008,45)









##############################################################################
### INTERPOLATE FISH POSITIONS SAVE THEM AS A MySQL DATABASE
##############################################################################
# to use this function, the database and tables should already be defined and connected
##############################################################################
fillPathInterp = function(tagName, beaconName, deployment, year, psr=TRUE, ...)
  # 'beaconName' is the desired beacon, i.e. b1
  # 'year' because I do different things for different years, 2007, 2008, 2009
  # 'deployment' is the experiment designation, i.e. hb1 for 2009 experiments
  # 'psr'  use the 'psr' or 'no psr' ALPS output
  # tagName="t91"; beaconName="b1"; deployment="test"; year="2009"; psr=TRUE; 
  # tagName="t38"; beaconName="b1"; deployment="hb2"; year="2009"; psr=TRUE;  
{
  tagID = substr(tagName,2,100)
  tagType = substr(tagName,1,1)
  beaconID = substr(beaconName,2,100) 
  
  # settings that change for each deployment
  for (i in 1:length(md)){ # i loops through all deployments
    if (deployment == md[[i]]$deployment){
      startUtime = md[[i]]$startUtime
      stopUtime = md[[i]]$stopUtime
    }  
  }
    
  # make the the database and dbTable names
  dbName = paste("db",deployment,sep="")
  #I now do all fish in one table...dbTname = paste(tagName, beaconName,"pathInterp", sep="")
  dbTname = "fishpaths"
  
  # connect to the db
  dbcon = dbConnect(MySQL(), user="root", password="zy0014", dbname=dbName)

  # interpolate fish positions for the chosen fish 
  fpath = interpolateALPSdata(tagName=tagName, beaconName=beaconName, 
    deployment=deployment, year=year, psr=psr, ...)
  
  # check to see if the table has had all the rows added yet and if the
  # 'utime' values are there.  When the tables are created they have one row and
  # the 'utime' value is set to '7777777'.  Also they get a column named
  # 'row_names' from somewhere.
  dbphrase = paste("SELECT utime from", dbTname, "WHERE row_names=1")   zzz this needs fixing because I deleted the column row_names
  res = dbSendQuery(dbcon, dbphrase)
  ready = fetch(res, n = -1)
  if (ready$utime == 7777777){ # then the table's not ready
    # so add rows for all the Utime, this takes a full day...
    for (i in startUtime:stopUtime){
      dbphrase = paste("INSERT INTO", dbTname, "(utime) VALUES (",i,")")
      dbGetQuery(dbcon, dbphrase) 
    }
    # now remove the first row (from when the table was created) 
    # and the first column (named 'row_names')
    dbphrase = "DELETE FROM fishpaths WHERE utime = 7777777;"
    dbGetQuery(dbcon, dbphrase)
    dbphrase = "ALTER TABLE fishpaths DROP COLUMN row_names;"
    dbGetQuery(dbcon, dbphrase)
  } 

  # do a check to see if the interpolated 'fpath' really goes from startUtime to
  # stopUtime
  # ... first get the values from the database
  dbphrase = "SELECT utime FROM fishpaths ORDER BY utime ASC LIMIT 1;"
  dbfirstTime = dbGetQuery(dbcon, dbphrase)
  dbphrase = "SELECT utime FROM fishpaths ORDER BY utime DESC LIMIT 1;"
  dblastTime = dbGetQuery(dbcon, dbphrase)  
  # ... now compare them all and give a warning...does this work when the function is called?
  if ( (fpath$data$utime[1] != startUtime) || (dbfirstTime != startUtime)){ 
    print("'startUtime's don't match.") }
  if ( (fpath$data$utime[length(fpath$data$utime)] != stopUtime) || 
       (dblastTime != stopUtime)) {
    print("'stopUtime's don't match.")}
          
  # save the interpolated points to the right table in the right database
  # one row/utime at a time...this takes about 3 hrs
  for ( i in 1:(length(fpath$data$utime)) ){   
    dbphrase = paste(
      "UPDATE", dbTname,
      "SET t01x=", fpath$data$easting[i], ", t01y=", fpath$data$northing[i],
        ", t01z=", fpath$data$depth[i], ", t01i=", fpath$data$interp[i], 
        ", t01s=", fpath$data$status[i],
      "WHERE utime=",fpath$data$utime[i],";")
    dbGetQuery(dbcon, dbphrase)
  }   
} # end of fillPathInterp()

# DANGER...THIS WILL TAKE A DAY OR TWO...
#fillPathInterp(tagName="t91", beaconName="b1", deployment="test", year="2009")
#fillPathInterp(tagName="t38", beaconName="b1", deployment="hb2", year="2009")  

dbphrase = paste("SELECT utime,",
   "t01x, t01y, t01z, t01i, t01s,",
   "t02x, t02y, t02z, t02i, t02s,",
   "t03x, t03y, t03z, t03i, t03s,",
   "t04x, t04y, t04z, t04i, t04s,",
   "t05x, t05y, t05z, t05i, t05s,",
   "t06x, t06y, t06z, t06i, t06s,",
   "t07x, t07y, t07z, t07i, t07s,",
   "t08x, t08y, t08z, t08i, t08s,",
   "t09x, t09y, t09z, t09i, t09s,",
   "t10x, t10y, t10z, t10i, t10s,",
   "t11x, t11y, t11z, t11i, t11s,",
   "t12x, t12y, t12z, t12i, t12s",
   "FROM fishpaths;", sep=" ")
bob=dbGetQuery(dbcon, dbphrase) 
 
plot(bob$utime, bob$t01x, pch=19, cex=0.1) 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
# now learn how to extract data from a db
res <- dbSendQuery(dbcon, "SELECT * from t38b1pathinterp")
data <- fetch(res, n = -1)  